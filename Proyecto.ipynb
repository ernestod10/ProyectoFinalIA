{
<<<<<<< HEAD
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c38f384",
   "metadata": {},
   "source": [
    "Proyecto Verificar la salud de las plantas de tomate usando CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "181e48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8a5ae983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, array_to_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from glob import glob\n",
    "#from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8de5dabe",
   "metadata": {},
   "source": [
    "Importamos el dataset y lo ponemos de tamaÃ±o 225x225 las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "de7dc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = [224, 224]\n",
    "inception = InceptionV3(input_shape=img_size + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53fb3790",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in inception.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55d325dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/train\\\\Bacterial_spot',\n",
       " 'dataset/train\\\\Early_blight',\n",
       " 'dataset/train\\\\healthy',\n",
       " 'dataset/train\\\\Late_blight',\n",
       " 'dataset/train\\\\Leaf_Mold',\n",
       " 'dataset/train\\\\Septoria_leaf_spot',\n",
       " 'dataset/train\\\\Spider_mites Two-spotted_spider_mite',\n",
       " 'dataset/train\\\\Target_Spot',\n",
       " 'dataset/train\\\\Tomato_mosaic_virus',\n",
       " 'dataset/train\\\\Tomato_Yellow_Leaf_Curl_Virus']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = glob('dataset/train/*')\n",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "373077a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(inception.output)\n",
    "prediction = Dense(len(folder), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f5da655",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Model(inputs=inception.input, outputs=prediction)\n",
    "#modelo.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "616d3b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='SGD',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67dde2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "37ab872b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#training y testing\n",
    "training_set = train_datagen.flow_from_directory('dataset/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/train',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2b503316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 338s 1s/step - loss: 4.3488 - accuracy: 0.7123 - val_loss: 1.7461 - val_accuracy: 0.8211\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 334s 1s/step - loss: 3.1039 - accuracy: 0.7653 - val_loss: 2.1644 - val_accuracy: 0.7954\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 341s 1s/step - loss: 2.4737 - accuracy: 0.7984 - val_loss: 3.7059 - val_accuracy: 0.7412\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 363s 1s/step - loss: 1.9447 - accuracy: 0.8210 - val_loss: 1.6361 - val_accuracy: 0.8235\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 366s 1s/step - loss: 1.8191 - accuracy: 0.8289 - val_loss: 1.1010 - val_accuracy: 0.8692\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 351s 1s/step - loss: 1.7202 - accuracy: 0.8395 - val_loss: 2.6790 - val_accuracy: 0.7800\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 338s 1s/step - loss: 1.4625 - accuracy: 0.8534 - val_loss: 1.9677 - val_accuracy: 0.8195\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 350s 1s/step - loss: 1.5538 - accuracy: 0.8518 - val_loss: 0.6673 - val_accuracy: 0.9100\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 336s 1s/step - loss: 1.3510 - accuracy: 0.8664 - val_loss: 1.0029 - val_accuracy: 0.8825\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 334s 1s/step - loss: 1.1831 - accuracy: 0.8754 - val_loss: 0.8341 - val_accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "result = modelo.fit(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=10,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0c002fd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Precision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ernes\\Documents\\GitHub\\ProyectoFinalIA\\Proyecto.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ernes/Documents/GitHub/ProyectoFinalIA/Proyecto.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Precision\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ernes/Documents/GitHub/ProyectoFinalIA/Proyecto.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(result\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mPrecision\u001b[39;49m\u001b[39m'\u001b[39;49m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain acc\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ernes/Documents/GitHub/ProyectoFinalIA/Proyecto.ipynb#X50sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(result\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_Precision\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval acc\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ernes/Documents/GitHub/ProyectoFinalIA/Proyecto.ipynb#X50sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Precision'"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "plt.plot(result.history['accuracy'], label='train acc')\n",
    "plt.plot(result.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2db530a50e225ed1d73ac4bc1072e70e666df75e63aa73173b5a7ceb276d62ca"
   }
  }
 },
=======
 "cells": [],
 "metadata": {},
>>>>>>> parent of f2c83e9 (aaa)
 "nbformat": 4,
 "nbformat_minor": 5
}
